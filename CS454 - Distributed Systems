# CS454

## Introduction - Slides 1 + Chapter 1

### Distributed System

- Characteristic features
  - Autonomous computing elements, called NODES, can be software or hardware
  - Appear as a single system, nodes COLLABORATE
- Each node is independent, each with its own notion of time
  - There is no global clock
- DS often organized as an overlay network
  - Example: p2p systems
  - Structured: Each node has well defined neighbors (tree/ring)
  - Unstructured: Randomly selected nodes

### Design goals

- Support of sharing resources
- Distribution Transparency
  - Degree of transparency
    - Unable to hide failures
    - transparency costs performance
- Being open
  - Systems should have defined interfaces
  - easy to interoperate/portable/extensible
- Scalability
  - Size scalability: increase # users or processes
    - Root causes:
      - Computation, limited by CPU + speed
      - Storage capacity, limited by transfer rate
      - Network capacity, can only receive and send so quickly
  - Geographical scalability: resources + their distance between nodes
    - Root causes:
      - Most systems assume synchronous interactions, latency prohibits this
      - WAN is unreliable, limited bandwidth
      - Lack of multipoint communication, can't broadcast -> Need to develop naming & directory services
  - Administrative scalability: # of admin domains

### Scaling Techniques

- Hide communication latencies (Geographical)
  - Use async communication
    - Not all applications have better things to do, improve latency by reducing communication (ask client to do more work)
  - Have separate handlers for incoming response
- Partitioning & Distribution
  - Decentralized naming schemes (DNS) and information systems (WWW)
- Replication & Caching
  - Replicate files / caching closer to the client
  - Caching causes problems with consistency, needs global synchronization, hard and expensive, usually not scalable

### Types of Distributed Computing

- High Performance DS
  - Operate in parallel
- Cluster Computing
  - Single compute intensive program runs in parallel on multiple machines
  - One master node, controls compute slave nodes
  - All same OS, mostly same hardware
- Grid Computing
  - Heterogeneous
  - Dispersed across several orgs
  - For collaboration, uses virtual orgs to auth resources
- Cloud computing
  - Distinction of 4 layers
    - Hardware (IaaS)
    - Infrastructure, (IaaS) VMs + Storage
    - Platforms, (PaaS) Higher level extraction
    - Applications, (SaaS)

  ### Distributed Transaction Processing

  - Encapsulate in transaction calls with Transaction Processing Manager
  - Use Remote Procedure Calls to request another component to do work, leading to:
  - Remote Method Invocations (RMI)
  - Since both RPC and RMI need caller + callee to be active, have moved to Message Oriented Middleware (MOM) think PUBSUB

  ### Distributed Pervasive Systems

  - The internet of things, components are smaller, sensors almost

## Architecture Styles - Slides 2 + Chapter 2

- Layered architecture
  - Organized in layers, usually only make downcalls, sometimes can call up
  - Application Layering
    - Many systems that are backed by database
    - App interface level
    - processing level
    - data level
- Object-based architecture
  - components are objects, connected through procedure calls
  - objects my be placed on different machines
- Resource-centered architecture
    - RESTful architecture (PUT/GET/DELETE/POST)
- Event-based architecture
    - PUBSUB

### Middleware

- Use of wrappers + interfaces
- 1:1 wrapper requires O(n^2) wrappers, (N x N-1)
- Use broken, requires 2N = O(N) wrappers

**Interceptors**

- Intercept call between App/middleware + Middleware/Server

**Multi-tiered centralized System architectures**

- Single-tiered: Dumb terminal/mainframe
- Two-tiered: Client/server
- Three-tiered: Each layer on separate machine (UI/APP/DB)

**Structured P2P**

- Use hash function to get to neighbor responsible for holding onto key
- Has shortcuts to other nodes

**Unstructured P2P**

- Searching
    - Flooding, pass request to all neighbors, if a node has seen it before they ignore, otherwise continues for certain # of hops
    - Random walk, randomly walks until it finds it
- Super-Peer Networks
    - Use index servers to improve performance
    - They tell you which CDN to use
    - Super-Peers maintain index and ask as a broker, collecting data on resource usage and node availability
    - Every regular peer is a weak peer, when they join they attach to SP.

**Edge-Server systems**

- Deploy servers at the edge of the network

## Jan 25th

**Scalability**

- Vertical distribution - partitioning of service
- Horizontal distribution - replication of service

Vertical Distribution
  - Then you need both servers to be up to provide the service, 0.95*n servers that you need, for 2 -> 0.9
  - Increasing the chance of failure if all of the components need to be up and running (any server is a point of failure)

Horizontal Distribution
  - Managing updates in the replicas is a key challenge

**No solutions, just tradeoffs**

### Middleware Layer

- (Un)marshaling of data, necessary for integrated systems
- Naming protocols, to share resources
- Security protocols, for secure communications
- Scaling mechanisms, for replication and caching

### Types of Communication

- Synchronous vs Async
  - Sync: We block, wait for result, unblock handle response
  - Async: Don't block, let people do what they want
- Transient vs Persistent communication
  - Transient: Client discards message when it 's not delivered to the server (most)
  - Persistent: Recipient doesn't need to be there, communication infrastructure stores message if it's not there

### Basic RPC operation

- Remote procedure call
  - Call remote procedure
  - Call local procedure and return results
  - Return from call
- Communication between caller & callee are transparent

### RPC: Parameter Passing

- Endianess: Order of parameters
- Little Endian: R to L (most significant byte on the R)
- Big Endian: L to R
- Wrapping parameter means transforming into a sequence of bytes
- Client & Server have to agree on the same encoding
- Copy/Restore Semantics -> Client sends value to server, server changes, passes copy with changes back, client restores the change

## Tues, Jan 30th

### Server

  - Create Socket, set aside OS resources
  - Bind to a local address or port
  - Listen, wiling to accept any connections
  - Accept, backs the server until an incoming connection request arrives
  - Read
  - Write
  - Close

### Client

  - Socket, no need to bind this socket to a port
  - Connect, call connect with IP, port #, then blocks until connection is established
  - Write,
  - Read,
  - Close when finished, terminate connection

Server Accept + Client connect is transient synchronous

### Message-Oriented Middleware

Idea: Async persistent communication through support of middleware-level queues
Queues correspond to buffers at communication servers

*Operations*

- Put: append message to queue
- Get: Block until queue is nonempty, then remove first message
- Poll: check q for messages, remove the first, never block
- Notify: Install a handler to be called when a message is put into the q

# LARGE JUMP

## Coordination

**The Happened-Before Relationship**

- must agree on the order in which events occur (does not matter about time)
- a -> b, a comes before b
- if a is sending and b is the receipt, a->b
- if a->b and b->c then a->c
- with **concurrent events** nothing can be said about which happen or happens first
- if a -> b then C9a) < C9b)

## Transactions

**Transaction Primitives**
- BEGIN_TRANSACTION
- END_TANSACTION (EOT)
  - end and try to commit
- ABORT_TRANSACTION
  - kill and restore old values
- READ
- WRITE

**Key**

- Make them happen serially
- If each action is consistent then the end will be consistent

**Conflicts**

- Read Read No
- Read Write Yes
- Write Read Yes

**Distributed Transaction Serializability**

- for global transactions (global history) to be serializable
  - each local history is serializable
  - two conflicting operations should be in the same relative order in all of the local histories where they appear together

**Concurrency Control**

- Achieve consistency and concurrency through these 2 algorithms
- Two-phase locking-based (2PL)
  - Centralized 2PL
  - Distributed 2PL
- Timestamp Ordering (TO)
  - Basic TO
  - Multiversion TO

**Locking-Based Algorithms**

- Ask scheduler (lock manager) for lock
- Either read lock (rl/shared lock) or write lock (wl/exclusive lock)

**Two-Phase Locking (2PL)**

- Transaction locks object before using it
- When object is locked, others must wait
- When it releases lock, it may not request another
- **Strict 2PL**, hold locks until the end of transaction

**Centralized 2PL**

- Only one 2PL scheduler for the system
- All lock requests go to this dude

**Distributed 2PL**

- 2PL schedulers at each site
- handles lock requests for objects at that site

**Timestamp Ordering**

- Transaction given unique timestamp
- TS attaches timestamp to all transactions
- Each object assigned write and read timestamp (wts) or (rts)
- Conflicting operations resolved by timestamp
  - Basic:
  - READING: if ts(Ti) < wts(x), reject, otherwise, accept (started before it was written to)
  - WRITING: if (ts(Ti) < rts(x) or Ts(Ti) < wts(x) then reject, else accept
    - should not write to an object that was read after it started

## Majority Quorum

- To read a file: N replicas exist
  - Client needs to assemble a READ QUORUM, collection of NR servers or more
- Similar WRITE QUORUM of NW servers
- NR + NW > N
  - prevent read-write conflicts
- NW > N/2
  - prevent write-write conflicts

-> Create N_R and N_W with S_1 in it, so C is optimized for performance
  - S_1 is always in the set, so C will always have the most up to date reads and write
  - Just randomly assign the other 2, it doesn't matter
  - show that it meets the requirements of NR + NW > N and NW > N/2

## 2PC Coordinator component + Participation components

1. coord fails after it sends PREPARE and before it receives PREPARED from participants
2. participant fails after PRPEARED to coord and before it receives GLOBAL-COMMIT or GLOBAL ABORT

Assume:
  - Coordinator processes at least some of global transaction
  - messages aren't lost, if wait for timeout, the message has failed

## Atomic Multicast

- Ex: Deliver update to distributed network, as a transaction, either full update or not
- We have P crashing AFTER completing multicast and a situation where P crashes before it got a chance to request update

## Distributed Commit

- Atomic multicasting is an example of this
- Have an operation performed by each member or none at all
- Use of coordinator
  - Tells processes involved (participants) whether or not to perform the operation
  - (One-phase commit protocol)
  - There is no way to tell coordinator if they can't actually perform it
- TWO-PHASE COMMIT PROTOCOL
  - 2 phases, of 2 steps
  - Coordinator sends VOTE-REQUEST to all participants
  - When participant receives either returns VOTE-COMMIT (says it's prepared to coord) or VOTE-ABORT (not ready)
  - Coord collects all votes, if all say VOTE-COMMIT, then sends GLOBAL-COMMIT to all participants, if not all agree, GLOBAL-ABORT
  - Each participants waits for reaction from coord. if GLOBAL-COMMIT then it goes through, otherwise, aborts
  - First phase is VOTING PHASE, second is DECISION PHASE
